# LangGraph æ¶æ„è¿ç§»æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£è®°å½•äº† GustoBot ä»æ—§ç‰ˆ LangGraph æ¶æ„è¿ç§»åˆ°ç°ä»£åŒ–çº¯å‡½æ•°èŠ‚ç‚¹æ¶æ„çš„è¿‡ç¨‹ã€‚

## ä¸»è¦æ”¹è¿›

### 1. **å‡çº§ LangGraph ç‰ˆæœ¬**
- **æ—§ç‰ˆæœ¬**: `langgraph==0.0.25`
- **æ–°ç‰ˆæœ¬**: `langgraph==0.2.60` + `langgraph-checkpoint==2.0.8`

### 2. **çŠ¶æ€ç®¡ç†ä¼˜åŒ–**
**ä¹‹å‰**: ä½¿ç”¨ Pydantic `BaseModel`
```python
class ConversationState(BaseModel):
    message: str
    session_id: Optional[str] = None
    # ...

    def to_dict(self) -> Dict[str, Any]:
        return self.model_dump(exclude_none=True)
```

**ç°åœ¨**: ä½¿ç”¨ `TypedDict` (æ¨èçš„ LangGraph æ¨¡å¼)
```python
class ConversationState(TypedDict):
    message: str  # Required
    session_id: NotRequired[Optional[str]]
    # ...
```

**ä¼˜ç‚¹**:
- æ›´å¥½çš„ç±»å‹æ£€æŸ¥å’Œ IDE æ”¯æŒ
- ä¸ LangGraph åŸç”Ÿé›†æˆæ›´å¥½
- æ›´è½»é‡çº§ï¼Œæ— éœ€åºåˆ—åŒ–/ååºåˆ—åŒ–å¼€é”€

### 3. **Agent æ¶æ„é‡æ„**

#### ä¹‹å‰: ç±»å¼ Agent
æ¯ä¸ª Agent æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç±»ï¼š
```python
class RouterAgent(BaseAgent):
    def __init__(self, llm_client: Optional[LLMClient] = None):
        super().__init__(name="RouterAgent", description="...")
        self.llm_client = llm_client

    async def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        # è·¯ç”±é€»è¾‘...
        pass
```

#### ç°åœ¨: çº¯å‡½æ•°èŠ‚ç‚¹
æ‰€æœ‰ Agent é€»è¾‘æå–ä¸ºçº¯å‡½æ•°ï¼š
```python
async def route_question(
    state: ConversationState,
    llm_client: Optional[LLMClient] = None,
) -> ConversationState:
    """Pure function that takes state and returns updated state."""
    # è·¯ç”±é€»è¾‘...
    return {**state, "route": decision["route"], ...}
```

**ä¼˜ç‚¹**:
- æ›´å®¹æ˜“æµ‹è¯•ï¼ˆçº¯å‡½æ•°ï¼Œæ— å‰¯ä½œç”¨ï¼‰
- æ›´å®¹æ˜“ç»„åˆå’Œå¤ç”¨
- ä¾èµ–æ³¨å…¥æ›´æ¸…æ™°
- ç¬¦åˆ LangGraph æœ€ä½³å®è·µ

### 4. **æµå¼è¾“å‡ºæ”¯æŒ**

æ–°æ¶æ„åŸç”Ÿæ”¯æŒæµå¼è¾“å‡ºï¼š

```python
# åœ¨ SupervisorAgent
async def stream(self, input_data: Dict[str, Any]):
    """Stream workflow execution events."""
    async for event in self.workflow.astream(initial_state):
        yield event

# åœ¨ API
@router.post("/stream")
async def chat_stream(request: ChatRequest, supervisor = Depends(get_supervisor)):
    async def event_generator() -> AsyncIterator[str]:
        async for event in supervisor.stream(input_data):
            yield f"data: {json.dumps(event_data)}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

## æ–‡ä»¶ç»“æ„å˜åŒ–

### æ–°å¢æ–‡ä»¶
```
app/agents/
â”œâ”€â”€ nodes.py                      # æ–°å¢: æ‰€æœ‰çº¯å‡½æ•°èŠ‚ç‚¹
â”œâ”€â”€ supervisor_agent_v2.py        # æ–°å¢: é‡æ„åçš„ SupervisorAgent
â””â”€â”€ state_models.py               # ä¿®æ”¹: ä½¿ç”¨ TypedDict
```

### ä¿ç•™æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
```
app/agents/
â”œâ”€â”€ base_agent.py                 # ä¿ç•™: å¦‚æœéœ€è¦ç±»å¼ Agent
â”œâ”€â”€ router_agent.py               # ä¿ç•™: æ—§ç‰ˆç±»å¼å®ç°
â”œâ”€â”€ knowledge_agent.py            # ä¿ç•™: æ—§ç‰ˆç±»å¼å®ç°
â”œâ”€â”€ chat_agent.py                 # ä¿ç•™: æ—§ç‰ˆç±»å¼å®ç°
â””â”€â”€ supervisor_agent.py           # ä¿ç•™: æ—§ç‰ˆå®ç°
```

## å·¥ä½œæµå›¾ç»“æ„

### èŠ‚ç‚¹å®šä¹‰å˜åŒ–

**ä¹‹å‰**:
```python
# SupervisorAgent._build_graph()
async def route_node(state: dict) -> dict:
    conv = ConversationState.model_validate(state)
    route_result = await self.router.process({...})
    # ...
```

**ç°åœ¨**:
```python
# supervisor_agent_v2.py
from functools import partial

# ä½¿ç”¨ partial ç»‘å®šä¾èµ–
graph.add_node(
    "route",
    partial(route_question, llm_client=self.llm_client)
)
```

### å®Œæ•´å·¥ä½œæµ

```
START
  â†“
prepare_context  (åŠ è½½å†å², å‡†å¤‡ç¼“å­˜ä¸Šä¸‹æ–‡)
  â†“
check_cache     (æ£€æŸ¥è¯­ä¹‰ç¼“å­˜)
  â†“
[æ¡ä»¶åˆ†æ”¯: cached? â†’ finalize : route]
  â†“
route           (è·¯ç”±åˆ†ç±»: knowledge/chat/reject)
  â†“
[æ¡ä»¶åˆ†æ”¯: knowledge â†’ knowledge_node]
           [chat â†’ chat_node]
           [reject â†’ finalize]
  â†“
finalize        (æŒä¹…åŒ–å†å², æ›´æ–°ç¼“å­˜)
  â†“
END
```

## è¿ç§»æ­¥éª¤

### Step 1: æ›´æ–°ä¾èµ–
```bash
pip install -r requirements.txt
```

### Step 2: æ›´æ–° API ç«¯ç‚¹å¯¼å…¥

**æ—§ä»£ç ** (`app/api/chat_router.py`):
```python
def get_supervisor():
    from ..agents import SupervisorAgent, RouterAgent, KnowledgeAgent, ChatAgent

    router_agent = RouterAgent()
    knowledge_agent = KnowledgeAgent(knowledge_service=knowledge_service)
    chat_agent = ChatAgent()

    supervisor = SupervisorAgent(
        router=router_agent,
        knowledge=knowledge_agent,
        chat=chat_agent,
        ...
    )
```

**æ–°ä»£ç **:
```python
def get_supervisor():
    from ..agents.supervisor_agent_v2 import SupervisorAgent
    from ..knowledge_base import KnowledgeService

    knowledge_service = KnowledgeService()
    llm_client = LLMClient()

    supervisor = SupervisorAgent(
        knowledge_service=knowledge_service,
        llm_client=llm_client,
        semantic_cache=_semantic_cache,
        history_store=_history_store,
    )
```

### Step 3: ä½¿ç”¨æ–° API

#### æ ‡å‡†è°ƒç”¨ï¼ˆéæµå¼ï¼‰
```python
# POST /api/v1/chat/
result = await supervisor.process({
    "message": "å¦‚ä½•åšçº¢çƒ§è‚‰ï¼Ÿ",
    "session_id": "xxx",
    "user_id": "user123"
})
# è¿”å›: {"answer": "...", "type": "knowledge", "metadata": {...}}
```

#### æµå¼è°ƒç”¨
```python
# POST /api/v1/chat/stream
async for event in supervisor.stream(input_data):
    # æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåä¼šäº§ç”Ÿäº‹ä»¶
    print(event)
```

## API ç«¯ç‚¹å˜åŒ–

| ç«¯ç‚¹ | æ–¹æ³• | çŠ¶æ€ | è¯´æ˜ |
|-----|------|-----|------|
| `/api/v1/chat/` | POST | âœ… å…¼å®¹ | æ ‡å‡†èŠå¤©æ¥å£ï¼Œä½¿ç”¨æ–° SupervisorAgent |
| `/api/v1/chat/stream` | POST | ğŸ†• æ–°å¢ | æµå¼èŠå¤©æ¥å£ (SSE) |
| `/api/v1/chat/status` | GET | âœ… æ›´æ–° | è¿”å›æ–°ç‰ˆæœ¬ä¿¡æ¯ |

## æµ‹è¯•å»ºè®®

### 1. å•å…ƒæµ‹è¯•èŠ‚ç‚¹å‡½æ•°
```python
# tests/test_nodes.py
import pytest
from app.agents.nodes import route_question
from app.agents.state_models import ConversationState

@pytest.mark.asyncio
async def test_route_question():
    state: ConversationState = {"message": "å¦‚ä½•åšçº¢çƒ§è‚‰ï¼Ÿ"}
    result = await route_question(state, llm_client=None)

    assert result["route"] == "knowledge"
    assert result["confidence"] > 0.5
```

### 2. é›†æˆæµ‹è¯•å·¥ä½œæµ
```python
# tests/test_supervisor_v2.py
@pytest.mark.asyncio
async def test_supervisor_workflow():
    supervisor = SupervisorAgent(
        knowledge_service=mock_knowledge_service,
        llm_client=mock_llm_client
    )

    result = await supervisor.process({
        "message": "ä½ å¥½",
        "session_id": "test_session"
    })

    assert result["answer"]
    assert result["type"] in ["knowledge", "chat", "reject"]
```

### 3. æµå¼è¾“å‡ºæµ‹è¯•
```python
@pytest.mark.asyncio
async def test_streaming():
    events = []
    async for event in supervisor.stream(input_data):
        events.append(event)

    assert len(events) > 0
    # éªŒè¯æœ€ç»ˆçŠ¶æ€åŒ…å«ç­”æ¡ˆ
```

## æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | æ—§æ¶æ„ | æ–°æ¶æ„ | æ”¹è¿› |
|-----|-------|-------|-----|
| ç±»å‹å®‰å…¨ | Pydantic è¿è¡Œæ—¶éªŒè¯ | TypedDict ç¼–è¯‘æ—¶æ£€æŸ¥ | âœ… æ›´å¿« |
| å†…å­˜å ç”¨ | æ¯æ¬¡åˆ›å»º Pydantic å¯¹è±¡ | ç›´æ¥æ“ä½œ dict | âœ… æ›´ä½ |
| æµ‹è¯•å¤æ‚åº¦ | éœ€è¦ mock å¤šä¸ª Agent ç±» | æµ‹è¯•çº¯å‡½æ•°å³å¯ | âœ… æ›´ç®€å• |
| æµå¼æ”¯æŒ | ä¸æ”¯æŒ | åŸç”Ÿæ”¯æŒ | ğŸ†• æ–°åŠŸèƒ½ |

## å¸¸è§é—®é¢˜

### Q1: æ—§ä»£ç è¿˜èƒ½ç”¨å—ï¼Ÿ
**A**: å¯ä»¥ã€‚æ—§çš„ Agent ç±»ï¼ˆ`router_agent.py`, `knowledge_agent.py`, `chat_agent.py`ï¼‰ä»ç„¶ä¿ç•™ï¼Œä½†æ¨èè¿ç§»åˆ°æ–°æ¶æ„ã€‚

### Q2: å¦‚ä½•é€æ­¥è¿ç§»ï¼Ÿ
**A**:
1. å…ˆåœ¨å¼€å‘ç¯å¢ƒæµ‹è¯•æ–° API `/api/v1/chat/` ï¼ˆå·²è‡ªåŠ¨ä½¿ç”¨æ–° SupervisorAgentï¼‰
2. ç¡®è®¤åŠŸèƒ½æ­£å¸¸åï¼Œé€æ­¥åˆ‡æ¢ç”Ÿäº§æµé‡
3. æ—§ Agent ç±»å¯ä»¥ä¿ç•™ä¸€æ®µæ—¶é—´ä½œä¸ºå¤‡ç”¨

### Q3: æµå¼è¾“å‡ºå¦‚ä½•åœ¨å‰ç«¯ä½¿ç”¨ï¼Ÿ
**A**:
```javascript
// ä½¿ç”¨ EventSource æˆ– fetch
const response = await fetch('/api/v1/chat/stream', {
  method: 'POST',
  headers: {'Content-Type': 'application/json'},
  body: JSON.stringify({message: 'å¦‚ä½•åšçº¢çƒ§è‚‰ï¼Ÿ'})
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const {done, value} = await reader.read();
  if (done) break;

  const chunk = decoder.decode(value);
  const lines = chunk.split('\n\n');

  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const data = JSON.parse(line.slice(6));
      console.log('Event:', data);
    }
  }
}
```

### Q4: TypedDict å’Œ Pydantic æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
**A**:
- **TypedDict**: é™æ€ç±»å‹æç¤ºï¼Œç¼–è¯‘æ—¶æ£€æŸ¥ï¼Œé›¶è¿è¡Œæ—¶å¼€é”€
- **Pydantic**: è¿è¡Œæ—¶éªŒè¯ï¼Œæä¾›æ•°æ®è½¬æ¢å’ŒéªŒè¯åŠŸèƒ½
- **é€‰æ‹©**: LangGraph æ¨è TypedDict ç”¨äºçŠ¶æ€ï¼ŒPydantic ç”¨äº API è¾“å…¥è¾“å‡º

## ä¸‹ä¸€æ­¥ä¼˜åŒ–å»ºè®®

1. **æ·»åŠ æŒä¹…åŒ–æ£€æŸ¥ç‚¹**
   ```python
   from langgraph.checkpoint import MemorySaver

   checkpointer = MemorySaver()
   workflow = graph.compile(checkpointer=checkpointer)
   ```

2. **å¯è§†åŒ–å·¥ä½œæµ**
   ```python
   from IPython.display import Image

   Image(supervisor.workflow.get_graph().draw_mermaid_png())
   ```

3. **æ·»åŠ  Human-in-the-loop**
   ```python
   graph.add_node("human_approval", human_approval_node)
   graph.add_edge("knowledge", "human_approval")
   ```

4. **ç›‘æ§å’Œè¿½è¸ª**
   ```python
   from langsmith import Client

   # ä½¿ç”¨ LangSmith è¿½è¸ªå·¥ä½œæµæ‰§è¡Œ
   ```

## å‚è€ƒèµ„æº

- [LangGraph å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [TypedDict æ–‡æ¡£](https://docs.python.org/3/library/typing.html#typing.TypedDict)
- [FastAPI Streaming](https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse)

## æ€»ç»“

æ–°æ¶æ„çš„ä¸»è¦ä¼˜åŠ¿ï¼š
- âœ… **æ›´å¥½çš„ç±»å‹å®‰å…¨**: TypedDict æä¾›ç¼–è¯‘æ—¶æ£€æŸ¥
- âœ… **æ›´æ˜“æµ‹è¯•**: çº¯å‡½æ•°èŠ‚ç‚¹ï¼Œæ— å‰¯ä½œç”¨
- âœ… **æ›´é«˜æ€§èƒ½**: å‡å°‘å¯¹è±¡åˆ›å»ºå’Œåºåˆ—åŒ–å¼€é”€
- âœ… **æµå¼æ”¯æŒ**: åŸç”Ÿæ”¯æŒå®æ—¶å“åº”
- âœ… **æ›´ç¬¦åˆæœ€ä½³å®è·µ**: éµå¾ª LangGraph æ¨èæ¨¡å¼

å»ºè®®å°½å¿«å®Œæˆè¿ç§»ä»¥äº«å—è¿™äº›æ”¹è¿›ï¼
