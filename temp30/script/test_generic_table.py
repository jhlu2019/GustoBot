"""
æµ‹è¯•é€šç”¨è¡¨ç»“æ„æ–¹æ¡ˆ

éªŒè¯ï¼š
1. ä»»æ„è¡¨ç»“æ„éƒ½èƒ½å¤„ç†
2. æ‰€æœ‰å­—æ®µå­˜å‚¨åœ¨ metadata ä¸­
3. JSON æŸ¥è¯¢åŠŸèƒ½æ­£å¸¸
"""
import os
import sys
from dotenv import load_dotenv
import psycopg2
import pandas as pd

load_dotenv()

# å–æ¶ˆä»£ç†
os.environ['http_proxy'] = ''
os.environ['https_proxy'] = ''
os.environ['all_proxy'] = ''

sys.path.insert(0, '/')

from app.core.config import Config
from app.services.vector_store_generic import VectorStoreWriterGeneric
from app.clients.embedding import EmbeddingClient


def test_arbitrary_table_structure():
    """æµ‹è¯•ä»»æ„è¡¨ç»“æ„"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 1: å¤„ç†ä»»æ„è¡¨ç»“æ„")
    print("=" * 60)

    config = Config()
    vector_writer = VectorStoreWriterGeneric(config)

    # æ¨¡æ‹Ÿä¸åŒçš„è¡¨ç»“æ„
    test_cases = [
        {
            "name": "ç”¨æˆ·è¡¨",
            "source_table": "users",
            "data": {
                "user_id": 1,
                "username": "zhangsan",
                "email": "zhangsan@example.com",
                "age": 25,
                "city": "åŒ—äº¬",
                "interests": "ç¼–ç¨‹, é˜…è¯», è¿åŠ¨"
            }
        },
        {
            "name": "è®¢å•è¡¨",
            "source_table": "orders",
            "data": {
                "order_id": "ORD001",
                "customer_name": "æå››",
                "product": "ç¬”è®°æœ¬ç”µè„‘",
                "price": 5999.00,
                "quantity": 1,
                "order_date": "2025-01-20"
            }
        },
        {
            "name": "æ–‡ç« è¡¨",
            "source_table": "articles",
            "data": {
                "article_id": 100,
                "title": "Python æœ€ä½³å®è·µ",
                "author": "ç‹äº”",
                "content": "æœ¬æ–‡ä»‹ç» Python å¼€å‘çš„æœ€ä½³å®è·µ...",
                "tags": ["python", "ç¼–ç¨‹", "æ•™ç¨‹"],
                "publish_date": "2025-01-15"
            }
        }
    ]

    items = []
    for case in test_cases:
        # ç”Ÿæˆç®€å•çš„æè¿°æ–‡æœ¬
        content = f"{case['name']}: " + ", ".join([f"{k}={v}" for k, v in case['data'].items()])

        items.append({
            "source_table": case["source_table"],
            "source_id": str(case["data"].get(list(case["data"].keys())[0])),
            "rewritten_content": content,
            "original_data": case["data"]
        })

        print(f"\n{case['name']}:")
        print(f"  æ•°æ®: {case['data']}")
        print(f"  æ–‡æœ¬: {content[:80]}...")

    # å­˜å‚¨
    try:
        count = vector_writer.upsert(items)
        print(f"\nâœ… æˆåŠŸå­˜å‚¨ {count} æ¡ä¸åŒè¡¨ç»“æ„çš„æ•°æ®")
        return True
    except Exception as e:
        print(f"\nâŒ å­˜å‚¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_json_queries():
    """æµ‹è¯• JSON æŸ¥è¯¢"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: JSON å­—æ®µæŸ¥è¯¢")
    print("=" * 60)

    conn = psycopg2.connect(
        host=os.getenv("PGHOST", "localhost"),
        port=os.getenv("PGPORT", "5432"),
        database=os.getenv("PGDATABASE", "vector_db"),
        user=os.getenv("PGUSER", "postgres"),
        password=os.getenv("PGPASSWORD", "postgres")
    )

    cursor = conn.cursor()

    # æµ‹è¯•å„ç§ JSON æŸ¥è¯¢
    queries = [
        {
            "name": "æŸ¥è¯¢ç”¨æˆ·è¡¨æ•°æ®",
            "sql": """
                SELECT
                    source_table,
                    metadata->>'username' as username,
                    metadata->>'email' as email,
                    metadata->>'city' as city
                FROM searchable_documents
                WHERE source_table = 'users'
            """
        },
        {
            "name": "æŸ¥è¯¢è®¢å•æ•°æ®",
            "sql": """
                SELECT
                    source_table,
                    metadata->>'customer_name' as customer,
                    metadata->>'product' as product,
                    metadata->>'price' as price
                FROM searchable_documents
                WHERE source_table = 'orders'
            """
        },
        {
            "name": "æŒ‰ JSON å­—æ®µç­›é€‰",
            "sql": """
                SELECT
                    source_table,
                    metadata->>'title' as title,
                    metadata->>'author' as author
                FROM searchable_documents
                WHERE metadata->>'author' = 'ç‹äº”'
            """
        },
        {
            "name": "æ£€æŸ¥å­—æ®µå­˜åœ¨",
            "sql": """
                SELECT
                    source_table,
                    COUNT(*) as count
                FROM searchable_documents
                WHERE metadata ? 'email'
                GROUP BY source_table
            """
        }
    ]

    all_passed = True
    for query in queries:
        print(f"\n{query['name']}:")
        print(f"SQL: {query['sql'].strip()[:100]}...")

        try:
            cursor.execute(query['sql'])
            results = cursor.fetchall()

            if results:
                print(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(results)} æ¡ç»“æœ")
                for i, row in enumerate(results[:3], 1):
                    print(f"  [{i}] {row}")
            else:
                print("âš ï¸  æŸ¥è¯¢æˆåŠŸä½†æ— ç»“æœ")

        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            all_passed = False

    cursor.close()
    conn.close()

    return all_passed


def test_real_excel_data():
    """æµ‹è¯•çœŸå®çš„ Excel æ•°æ®ï¼ˆä¼ä¸šäº§å“ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: å¤„ç†çœŸå® Excel æ•°æ®")
    print("=" * 60)

    try:
        # è¯»å– Excel
        df = pd.read_excel('data/data.xlsx', sheet_name='ä¼ä¸šäº§å“')
        print(f"åŠ è½½äº† {len(df)} æ¡ä¼ä¸šäº§å“æ•°æ®")

        # æ˜¾ç¤ºå­—æ®µ
        print(f"å­—æ®µ: {list(df.columns)}")

        # å¤„ç†å‰ 3 æ¡
        config = Config()
        vector_writer = VectorStoreWriterGeneric(config)

        items = []
        for idx, row in df.head(3).iterrows():
            row_dict = {k: (None if pd.isna(v) else v) for k, v in row.to_dict().items()}

            # ç”Ÿæˆç®€å•æè¿°
            company = row_dict.get('company_name(ä¼ä¸šåç§°)', '')
            product = row_dict.get('name(äº§å“åç§°)', '')
            content = f"{company} çš„äº§å“ {product}"

            items.append({
                "source_table": "ä¼ä¸šäº§å“_excel",
                "source_id": str(idx),
                "rewritten_content": content,
                "original_data": row_dict
            })

            print(f"\nå¤„ç†ç¬¬ {idx+1} æ¡:")
            print(f"  å…¬å¸: {company}")
            print(f"  äº§å“: {product}")
            print(f"  åŸå§‹å­—æ®µæ•°: {len(row_dict)}")

        # å­˜å‚¨
        count = vector_writer.upsert(items)
        print(f"\nâœ… æˆåŠŸå­˜å‚¨ {count} æ¡ Excel æ•°æ®")

        # éªŒè¯æŸ¥è¯¢
        print("\néªŒè¯å­˜å‚¨çš„æ•°æ®:")
        conn = psycopg2.connect(
            host=os.getenv("PGHOST", "localhost"),
            port=os.getenv("PGPORT", "5432"),
            database=os.getenv("PGDATABASE", "vector_db"),
            user=os.getenv("PGUSER", "postgres"),
            password=os.getenv("PGPASSWORD", "postgres")
        )

        cursor = conn.cursor()
        cursor.execute("""
            SELECT
                source_table,
                metadata->>'company_name(ä¼ä¸šåç§°)' as company,
                metadata->>'name(äº§å“åç§°)' as product,
                metadata->>'brief(ç®€ä»‹)' as brief
            FROM searchable_documents
            WHERE source_table = 'ä¼ä¸šäº§å“_excel'
            LIMIT 3
        """)

        results = cursor.fetchall()
        for i, row in enumerate(results, 1):
            print(f"  [{i}] å…¬å¸: {row[1]}, äº§å“: {row[2]}")

        cursor.close()
        conn.close()

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 70)
    print("é€šç”¨è¡¨ç»“æ„æ–¹æ¡ˆæµ‹è¯•")
    print("=" * 70)

    results = {}

    # æµ‹è¯• 1: ä»»æ„è¡¨ç»“æ„
    results["ä»»æ„è¡¨ç»“æ„"] = test_arbitrary_table_structure()

    # æµ‹è¯• 2: JSON æŸ¥è¯¢
    results["JSONæŸ¥è¯¢"] = test_json_queries()

    # æµ‹è¯• 3: çœŸå®æ•°æ®
    results["çœŸå®Excelæ•°æ®"] = test_real_excel_data()

    # æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)

    all_passed = True
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:20s}: {status}")
        if not result:
            all_passed = False

    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\né€šç”¨æ–¹æ¡ˆä¼˜åŠ¿:")
        print("  âœ… æ”¯æŒä»»æ„è¡¨ç»“æ„")
        print("  âœ… æ— éœ€ä¿®æ”¹ä»£ç ")
        print("  âœ… çµæ´»çš„ JSON æŸ¥è¯¢")
        print("  âœ… ç”¨æˆ·åªéœ€é…ç½® .env å’Œæç¤ºè¯")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())
