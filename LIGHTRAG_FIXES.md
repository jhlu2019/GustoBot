# LightRAG Node ä¿®å¤æ€»ç»“

## ğŸ¯ ä¿®å¤çš„é—®é¢˜

### 1. âŒ é”™è¯¯çš„ LightRAG åˆå§‹åŒ–æ–¹å¼

**é—®é¢˜**ï¼šä½¿ç”¨äº†ä¸å­˜åœ¨çš„ `llm_model_name` å’Œ `embedding_model_name` å‚æ•°

```python
# âŒ é”™è¯¯çš„æ–¹å¼
self.rag = LightRAG(
    working_dir=self.working_dir,
    llm_model_name=settings.OPENAI_MODEL,  # ä¸å­˜åœ¨çš„å‚æ•°
    llm_model_kwargs={...},
    embedding_model_name=settings.EMBEDDING_MODEL,  # ä¸å­˜åœ¨çš„å‚æ•°
    embedding_model_kwargs={...},
)
```

**ä¿®å¤**ï¼šä½¿ç”¨ `llm_model_func` å’Œ `embedding_func`

```python
# âœ… æ­£ç¡®çš„æ–¹å¼
self.rag = LightRAG(
    working_dir=self.working_dir,
    llm_model_func=self._llm_model_func,  # å‡½æ•°å¼•ç”¨
    embedding_func=EmbeddingFunc(
        embedding_dim=embedding_dim,
        max_token_size=self.max_token_size,
        func=self._embedding_func,
    ),
)
```

---

### 2. âŒ é”™è¯¯çš„ Neo4JStorage åˆå§‹åŒ–

**é—®é¢˜**ï¼šå°è¯•ç›´æ¥å®ä¾‹åŒ– `Neo4JStorage` å¹¶ä¼ é€’æ„é€ å‚æ•°

```python
# âŒ é”™è¯¯çš„æ–¹å¼
from lightrag.kg.neo4j_impl import Neo4JStorage

graph_storage = Neo4JStorage(
    uri=settings.NEO4J_URI,
    user=settings.NEO4J_USER,
    password=settings.NEO4J_PASSWORD,
    database=settings.NEO4J_DATABASE
)
```

**ä¿®å¤**ï¼šä½¿ç”¨å­—ç¬¦ä¸²åç§°ï¼ŒLightRAG ä¼šè‡ªåŠ¨åŠ è½½

```python
# âœ… æ­£ç¡®çš„æ–¹å¼
# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["NEO4J_URI"] = settings.NEO4J_URI
os.environ["NEO4J_USERNAME"] = settings.NEO4J_USER
os.environ["NEO4J_PASSWORD"] = settings.NEO4J_PASSWORD
os.environ["NEO4J_DATABASE"] = settings.NEO4J_DATABASE

# ä¼ é€’å­—ç¬¦ä¸²åç§°
graph_storage_type = "Neo4JStorage"  # ç±»å‹: str
self.rag = LightRAG(graph_storage=graph_storage_type)
```

---

### 3. âŒ QueryParam å‚æ•°é”™è¯¯

**é—®é¢˜**ï¼šä½¿ç”¨äº†ä¸å­˜åœ¨çš„ `max_token_for_text_unit` å‚æ•°

```python
# âŒ é”™è¯¯çš„æ–¹å¼
param = QueryParam(
    mode=retrieval_mode,
    top_k=self.top_k,
    max_token_for_text_unit=self.max_token_size,  # ä¸å­˜åœ¨çš„å‚æ•°
)
```

**ä¿®å¤**ï¼šåªä½¿ç”¨ `QueryParam` æ”¯æŒçš„å‚æ•°

```python
# âœ… æ­£ç¡®çš„æ–¹å¼
param = QueryParam(
    mode=retrieval_mode,
    top_k=self.top_k,
    # å…¶ä»–å‚æ•°å¦‚ max_entity_tokensã€max_relation_tokens å¯é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
)
```

---

### 4. âŒ graph_storage ç±»å‹é”™è¯¯

**é—®é¢˜**ï¼š`graph_storage` å˜é‡ç±»å‹ä¸º `str | None`ï¼Œå¯¼è‡´ç±»å‹æ£€æŸ¥é”™è¯¯

```python
# âŒ ç±»å‹é”™è¯¯
graph_storage = "Neo4JStorage" if ... else None  # str | None
```

**ä¿®å¤**ï¼šå§‹ç»ˆä½¿ç”¨å­—ç¬¦ä¸²ç±»å‹

```python
# âœ… ç±»å‹æ­£ç¡®
graph_storage_type = "Neo4JStorage" if ... else "NetworkXStorage"  # str
```

---

### 5. âŒ Embedding å‡½æ•°è¿”å›ç±»å‹é”™è¯¯

**é—®é¢˜**ï¼š`openai_embed` è¿”å› `np.ndarray`ï¼Œä½†ç±»å‹æ³¨è§£å£°æ˜ä¸º `List[List[float]]`

```python
# âŒ ç±»å‹ä¸åŒ¹é…
async def _embedding_func(self, texts: List[str]) -> List[List[float]]:
    return await openai_embed(...)  # å®é™…è¿”å› np.ndarray
```

**ä¿®å¤**ï¼šä¿®æ­£è¿”å›ç±»å‹æ³¨è§£å¹¶æ·»åŠ  numpy å¯¼å…¥

```python
# âœ… ç±»å‹æ­£ç¡®
import numpy as np

async def _embedding_func(self, texts: List[str]) -> np.ndarray:
    """åµŒå…¥å‘é‡æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (len(texts), embedding_dim)"""
    return await openai_embed(
        texts=texts,
        model=settings.EMBEDDING_MODEL,
        api_key=settings.OPENAI_API_KEY,
        base_url=settings.OPENAI_API_BASE,
    )
```

---

## ğŸ“‹ å®Œæ•´çš„æ­£ç¡®å®ç°

### LLM å‡½æ•°

```python
async def _llm_model_func(
    self,
    prompt,
    system_prompt=None,
    history_messages=[],
    keyword_extraction=False,
    **kwargs
) -> str:
    """LLM æ¨¡å‹å‡½æ•°ï¼Œç”¨äº LightRAG è°ƒç”¨"""
    return await openai_complete_if_cache(
        model=settings.OPENAI_MODEL,
        prompt=prompt,
        system_prompt=system_prompt,
        history_messages=history_messages,
        api_key=settings.OPENAI_API_KEY,
        base_url=settings.OPENAI_API_BASE,
        **kwargs,
    )
```

### Embedding å‡½æ•°

```python
import numpy as np

async def _embedding_func(self, texts: List[str]) -> np.ndarray:
    """
    Embedding å‡½æ•°ï¼Œç”¨äº LightRAG è°ƒç”¨

    è¿”å› np.ndarrayï¼Œå½¢çŠ¶ä¸º (len(texts), embedding_dim)
    """
    return await openai_embed(
        texts=texts,
        model=settings.EMBEDDING_MODEL,
        api_key=settings.OPENAI_API_KEY,
        base_url=settings.OPENAI_API_BASE,
    )
```

### åˆå§‹åŒ– LightRAG

```python
async def initialize(self):
    """åˆå§‹åŒ– LightRAG å®ä¾‹"""
    # é…ç½® Neo4j
    if self.enable_neo4j and settings.NEO4J_URI:
        os.environ["NEO4J_URI"] = settings.NEO4J_URI
        os.environ["NEO4J_USERNAME"] = settings.NEO4J_USER
        os.environ["NEO4J_PASSWORD"] = settings.NEO4J_PASSWORD
        os.environ["NEO4J_DATABASE"] = settings.NEO4J_DATABASE
        graph_storage_type = "Neo4JStorage"
    else:
        graph_storage_type = "NetworkXStorage"

    # åˆ›å»º LightRAG å®ä¾‹
    self.rag = LightRAG(
        working_dir=self.working_dir,
        llm_model_func=self._llm_model_func,
        embedding_func=EmbeddingFunc(
            embedding_dim=int(settings.EMBEDDING_DIMENSION),
            max_token_size=self.max_token_size,
            func=self._embedding_func,
        ),
        graph_storage=graph_storage_type,
    )

    # åˆå§‹åŒ–å­˜å‚¨
    await self.rag.initialize_storages()
```

### æŸ¥è¯¢

```python
async def query(self, query: str, mode: Optional[str] = None) -> Dict[str, Any]:
    """æ‰§è¡Œ LightRAG æŸ¥è¯¢"""
    await self.initialize()

    retrieval_mode = mode or self.retrieval_mode

    # åˆ›å»ºæŸ¥è¯¢å‚æ•°
    param = QueryParam(
        mode=retrieval_mode,
        top_k=self.top_k,
    )

    # æ‰§è¡ŒæŸ¥è¯¢
    response = await self.rag.aquery(query, param=param)

    return {
        "response": response,
        "mode": retrieval_mode,
        "query": query
    }
```

---

## ğŸ” ä¸å®˜æ–¹ç¤ºä¾‹å¯¹æ¯”

### MongoDB ç¤ºä¾‹ï¼ˆå®˜æ–¹ï¼‰

```python
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=gpt_4o_mini_complete,  # âœ… å‡½æ•°
    embedding_func=embedding_func_instance,  # âœ… EmbeddingFunc
    graph_storage="MongoGraphStorage",  # âœ… å­—ç¬¦ä¸²
)
```

### Dickens ç¤ºä¾‹ï¼ˆå®˜æ–¹ï¼‰

```python
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=llm_model_func,  # âœ… å‡½æ•°
    embedding_func=EmbeddingFunc(  # âœ… EmbeddingFunc
        embedding_dim=int(os.getenv("EMBEDDING_DIM", "1024")),
        max_token_size=int(os.getenv("MAX_EMBED_TOKENS", "8192")),
        func=lambda texts: ollama_embed(...),
    ),
    # æ²¡æœ‰ graph_storage = ä½¿ç”¨é»˜è®¤ NetworkXStorage
)
```

### æœ¬é¡¹ç›®ï¼ˆä¿®å¤åï¼‰

```python
self.rag = LightRAG(
    working_dir=self.working_dir,
    llm_model_func=self._llm_model_func,  # âœ… å‡½æ•°
    embedding_func=EmbeddingFunc(  # âœ… EmbeddingFunc
        embedding_dim=embedding_dim,
        max_token_size=self.max_token_size,
        func=self._embedding_func,
    ),
    graph_storage=graph_storage_type,  # âœ… å­—ç¬¦ä¸²
)
```

**âœ… å®Œå…¨ä¸€è‡´ï¼**

---

## ğŸ“ QueryParam æ”¯æŒçš„å‚æ•°

æ ¹æ® LightRAG æºç ï¼Œ`QueryParam` æ”¯æŒä»¥ä¸‹å‚æ•°ï¼š

```python
@dataclass
class QueryParam:
    mode: Literal["local", "global", "hybrid", "naive", "mix", "bypass"] = "mix"
    only_need_context: bool = False
    only_need_prompt: bool = False
    response_type: str = "Multiple Paragraphs"
    stream: bool = False
    top_k: int = ...
    chunk_top_k: int = ...
    max_entity_tokens: int = ...
    max_relation_tokens: int = ...
    max_total_tokens: int = ...
    hl_keywords: list[str] = ...
    ll_keywords: list[str] = ...
    conversation_history: list[dict[str, str]] = ...
    history_turns: int = ...
    model_func: Callable | None = None
    user_prompt: str | None = None
    enable_rerank: bool = True
    include_references: bool = False
```

**æ³¨æ„**ï¼šæ²¡æœ‰ `max_token_for_text_unit` å‚æ•°ï¼

---

## ğŸ§ª æµ‹è¯•éªŒè¯

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š

```bash
python test_lightrag_node.py
```

### æµ‹è¯•è¦†ç›–ï¼š

1. âœ… LightRAG åˆå§‹åŒ–
2. âœ… Embedding åŠŸèƒ½
3. âœ… æ–‡æ¡£æ’å…¥
4. âœ… æŸ¥è¯¢åŠŸèƒ½ï¼ˆnaiveã€localã€globalã€hybridï¼‰
5. âœ… Neo4j é›†æˆï¼ˆå¯é€‰ï¼‰

---

## ğŸ‰ æ€»ç»“

æ‰€æœ‰ä¿®å¤å·²å®Œæˆï¼Œä»£ç ç°åœ¨ï¼š

- âœ… å®Œå…¨ç¬¦åˆ LightRAG å®˜æ–¹ API
- âœ… ç±»å‹æ£€æŸ¥é€šè¿‡
- âœ… æ”¯æŒ Neo4j å’Œ NetworkX ä¸¤ç§å›¾å­˜å‚¨
- âœ… å‚æ•°é…ç½®æ¸…æ™°ã€å¯ç»´æŠ¤
- âœ… ä¸å®˜æ–¹ç¤ºä¾‹ä»£ç é£æ ¼ä¸€è‡´

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **LightRAG GitHub**: https://github.com/HKUDS/LightRAG
- **å®˜æ–¹ç¤ºä¾‹**:
  - `examples/lightrag_openai_compatible_demo.py`
  - `examples/mongodb_demo.py`
- **ç±»å®šä¹‰**: `lightrag/__init__.py` ä¸­çš„ `LightRAG` å’Œ `QueryParam` ç±»
